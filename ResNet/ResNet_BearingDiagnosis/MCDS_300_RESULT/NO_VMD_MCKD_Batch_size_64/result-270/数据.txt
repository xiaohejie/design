D:\python\anaconda\envs\py310\python.exe D:/0_大型机械设备故障检测/参考代码/代码/0/ResNet_BearingDiagnosis/main.py
ResNet(
  (conv1): Conv1d(1, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (pool): AdaptiveAvgPool1d(output_size=1)
  (ACTClassifier): Sequential(
    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): AdaptiveAvgPool1d(output_size=1)
  )
  (act_fc): Linear(in_features=512, out_features=5, bias=True)
)
[10705, 1190]
using cpu device.
D:\python\anaconda\envs\py310\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
D:\python\anaconda\envs\py310\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Training accuracy:47.91219056515647Time:0
Training Loss:1.2302147497812312Time:0
Test accuracy:44.621848739495796Time:0
Test Loss:0.04447836034438189Time:0
Training accuracy:53.12470808033629Time:1
Training Loss:1.2780184418394542Time:1
Test accuracy:49.66386554621849Time:1
Test Loss:0.03823410482967601Time:1
Training accuracy:56.65576833255488Time:2
Training Loss:1.208335944348994Time:2
Test accuracy:48.48739495798319Time:2
Test Loss:0.05960709387514772Time:2
Training accuracy:76.05791686127978Time:3
Training Loss:0.5868835229174326Time:3
Test accuracy:63.94957983193277Time:3
Test Loss:0.03605062019925158Time:3
Training accuracy:80.11209715086409Time:4
Training Loss:0.5162670518571336Time:4
Test accuracy:63.445378151260506Time:4
Test Loss:0.029814208856149882Time:4
Training accuracy:96.43157403082671Time:5
Training Loss:0.16149613386222772Time:5
Test accuracy:76.38655462184875Time:5
Test Loss:0.016197135668842733Time:5
Training accuracy:94.94628678187763Time:6
Training Loss:0.1724022504410305Time:6
Test accuracy:73.10924369747899Time:6
Test Loss:0.03878042076816078Time:6
Training accuracy:96.64642690331621Time:7
Training Loss:0.11961956418379062Time:7
Test accuracy:72.85714285714286Time:7
Test Loss:0.026821400938915604Time:7
Training accuracy:99.92526856609061Time:8
Training Loss:0.02630512656479559Time:8
Test accuracy:80.25210084033614Time:8
Test Loss:0.013684654235839843Time:8
Training accuracy:96.23540401681457Time:9
Training Loss:0.11021809469088947Time:9
Test accuracy:72.43697478991596Time:9
Test Loss:0.03458108982118238Time:9
Training accuracy:95.36665109761793Time:10
Training Loss:0.13292117497454398Time:10
Test accuracy:72.85714285714286Time:10
Test Loss:0.02439724417293773Time:10
Training accuracy:93.75058383932742Time:11
Training Loss:0.1814201208432664Time:11
Test accuracy:70.92436974789916Time:11
Test Loss:0.009596771753134848Time:11
Training accuracy:88.15506772536197Time:12
Training Loss:0.3594149655462815Time:12
Test accuracy:69.74789915966386Time:12
Test Loss:0.03365365677521008Time:12
Training accuracy:99.82251284446521Time:13
Training Loss:0.020973743436382173Time:13
Test accuracy:82.01680672268908Time:13
Test Loss:0.0155058692483341Time:13
Training accuracy:98.53339560952826Time:14
Training Loss:0.0506044295612533Time:14
Test accuracy:77.3109243697479Time:14
Test Loss:0.024670580054531578Time:14
Training accuracy:99.33675852405418Time:15
Training Loss:0.026287423941449884Time:15
Test accuracy:79.74789915966386Time:15
Test Loss:0.021156932926979385Time:15
Training accuracy:95.75899112564223Time:16
Training Loss:0.10571795828233306Time:16
Test accuracy:73.02521008403362Time:16
Test Loss:0.03592732533687303Time:16
Training accuracy:93.07800093414292Time:17
Training Loss:0.1796863165930686Time:17
Test accuracy:66.97478991596638Time:17
Test Loss:0.0366681748077649Time:17
Training accuracy:91.40588510042036Time:18
Training Loss:0.22723651606031023Time:18
Test accuracy:68.57142857142857Time:18
Test Loss:0.03323278026420529Time:18
Training accuracy:100.0Time:19
Training Loss:0.002866968819467Time:19
Test accuracy:86.05042016806723Time:19
Test Loss:0.011534599496536896Time:19
Training accuracy:100.0Time:20
Training Loss:0.0012009605493906333Time:20
Test accuracy:87.3109243697479Time:20
Test Loss:0.011705069982704996Time:20
Training accuracy:100.0Time:21
Training Loss:0.0008951963777647348Time:21
Test accuracy:87.05882352941177Time:21
Test Loss:0.01948663407013196Time:21
Training accuracy:100.0Time:22
Training Loss:0.000719246962784134Time:22
Test accuracy:86.30252100840336Time:22
Test Loss:0.007985353870552128Time:22
Training accuracy:100.0Time:23
Training Loss:0.0005827321520876462Time:23
Test accuracy:87.3109243697479Time:23
Test Loss:0.019940233631294314Time:23
Training accuracy:100.0Time:24
Training Loss:0.00043755534554351883Time:24
Test accuracy:87.73109243697479Time:24
Test Loss:0.027662956814806Time:24
Training accuracy:100.0Time:25
Training Loss:0.00038201488153848036Time:25
Test accuracy:87.47899159663865Time:25
Test Loss:0.006398498310762293Time:25
Training accuracy:100.0Time:26
Training Loss:0.00036046536085150165Time:26
Test accuracy:88.0672268907563Time:26
Test Loss:0.012721144251462792Time:26
Training accuracy:100.0Time:27
Training Loss:0.00042524006759720893Time:27
Test accuracy:87.81512605042016Time:27
Test Loss:0.016282982385459065Time:27
Training accuracy:100.0Time:28
Training Loss:0.0002611847752500769Time:28
Test accuracy:87.39495798319328Time:28
Test Loss:0.011181425046520073Time:28
Training accuracy:100.0Time:29
Training Loss:0.0005714867502409184Time:29
Test accuracy:86.63865546218487Time:29
Test Loss:0.008422109459628579Time:29
Training accuracy:100.0Time:30
Training Loss:0.00031843473486661464Time:30
Test accuracy:87.39495798319328Time:30
Test Loss:0.01293369822141503Time:30
Training accuracy:100.0Time:31
Training Loss:0.00022684718209889964Time:31
Test accuracy:87.81512605042016Time:31
Test Loss:0.0182825056444697Time:31
Training accuracy:100.0Time:32
Training Loss:0.00019699339941926978Time:32
Test accuracy:88.65546218487395Time:32
Test Loss:0.02457829323135504Time:32
Training accuracy:100.0Time:33
Training Loss:0.00027777064284540293Time:33
Test accuracy:87.98319327731092Time:33
Test Loss:0.013486854168547302Time:33
Training accuracy:85.48341896310136Time:34
Training Loss:0.5678646399895758Time:34
Test accuracy:64.2016806722689Time:34
Test Loss:0.04491125475458738Time:34
Training accuracy:99.69173283512377Time:35
Training Loss:0.017497708394058616Time:35
Test accuracy:81.9327731092437Time:35
Test Loss:0.022294304150493206Time:35
Training accuracy:100.0Time:36
Training Loss:0.0008952231975059151Time:36
Test accuracy:87.98319327731092Time:36
Test Loss:0.007861054845216896Time:36
Training accuracy:100.0Time:37
Training Loss:0.0005998408349447513Time:37
Test accuracy:88.73949579831933Time:37
Test Loss:0.022267485867027474Time:37
Training accuracy:100.0Time:38
Training Loss:0.0009637500728414834Time:38
Test accuracy:87.14285714285714Time:38
Test Loss:0.016905739728142233Time:38
Training accuracy:100.0Time:39
Training Loss:0.0003671635112593395Time:39
Test accuracy:87.81512605042016Time:39
Test Loss:0.006897137746089647Time:39
Training accuracy:100.0Time:40
Training Loss:0.00032336987893887486Time:40
Test accuracy:88.73949579831933Time:40
Test Loss:0.010627413196724002Time:40
Training accuracy:100.0Time:41
Training Loss:0.00024300914754528188Time:41
Test accuracy:88.31932773109244Time:41
Test Loss:0.005727868921616498Time:41
Training accuracy:100.0Time:42
Training Loss:0.000259331522560785Time:42
Test accuracy:88.0672268907563Time:42
Test Loss:0.014062796520585773Time:42
Training accuracy:100.0Time:43
Training Loss:0.00022408087496001523Time:43
Test accuracy:88.57142857142857Time:43
Test Loss:0.01544147779961594Time:43
Training accuracy:100.0Time:44
Training Loss:0.00019048917560113027Time:44
Test accuracy:87.98319327731092Time:44
Test Loss:0.012623171445702304Time:44
Training accuracy:100.0Time:45
Training Loss:0.00017585009384320918Time:45
Test accuracy:87.98319327731092Time:45
Test Loss:0.016148773962710083Time:45
Training accuracy:100.0Time:46
Training Loss:0.000231145879409038Time:46
Test accuracy:87.98319327731092Time:46
Test Loss:0.006763491911046645Time:46
Training accuracy:100.0Time:47
Training Loss:0.0001517001789155434Time:47
Test accuracy:88.4873949579832Time:47
Test Loss:0.0018378844782083977Time:47
Training accuracy:100.0Time:48
Training Loss:0.0001386639131394044Time:48
Test accuracy:88.73949579831933Time:48
Test Loss:0.015065108227128742Time:48
Training accuracy:100.0Time:49
Training Loss:0.00013288385467495053Time:49
Test accuracy:88.57142857142857Time:49
Test Loss:0.009986615381320986Time:49
Training accuracy:100.0Time:50
Training Loss:0.00014437588250602952Time:50
Test accuracy:88.0672268907563Time:50
Test Loss:0.00839163515748096Time:50
Training accuracy:100.0Time:51
Training Loss:9.083811420771575e-05Time:51
Test accuracy:88.73949579831933Time:51
Test Loss:0.01018224043004653Time:51
Training accuracy:100.0Time:52
Training Loss:0.00010571851031197907Time:52
Test accuracy:88.90756302521008Time:52
Test Loss:0.017182047226849725Time:52
Training accuracy:100.0Time:53
Training Loss:9.707657127462358e-05Time:53
Test accuracy:88.4873949579832Time:53
Test Loss:0.005731494887536314Time:53
Training accuracy:100.0Time:54
Training Loss:0.00022457005891736662Time:54
Test accuracy:87.56302521008404Time:54
Test Loss:0.007271619203711758Time:54
Training accuracy:99.99065857076133Time:55
Training Loss:0.0015212408820709186Time:55
Test accuracy:85.96638655462185Time:55
Test Loss:0.012851166925510438Time:55
Training accuracy:100.0Time:56
Training Loss:0.000306169170971537Time:56
Test accuracy:87.22689075630252Time:56
Test Loss:0.01806071946600906Time:56
Training accuracy:100.0Time:57
Training Loss:0.00020107635788859635Time:57
Test accuracy:87.73109243697479Time:57
Test Loss:0.028684372461142662Time:57
Training accuracy:100.0Time:58
Training Loss:0.00023739199640837466Time:58
Test accuracy:86.89075630252101Time:58
Test Loss:0.014623856744846377Time:58
Training accuracy:100.0Time:59
Training Loss:0.00015109821937417996Time:59
Test accuracy:87.73109243697479Time:59
Test Loss:0.0022543468395201096Time:59
Training accuracy:100.0Time:60
Training Loss:0.00016711777888911802Time:60
Test accuracy:87.56302521008404Time:60
Test Loss:0.015443999026002003Time:60
Training accuracy:100.0Time:61
Training Loss:0.0001489478878334116Time:61
Test accuracy:87.14285714285714Time:61
Test Loss:0.014603351945636653Time:61
Training accuracy:100.0Time:62
Training Loss:0.00011418514390691806Time:62
Test accuracy:87.89915966386555Time:62
Test Loss:0.010015966912277607Time:62
Training accuracy:100.0Time:63
Training Loss:0.0001226640323704193Time:63
Test accuracy:87.81512605042016Time:63
Test Loss:0.01014652572760061Time:63
Training accuracy:100.0Time:64
Training Loss:0.00011407531958181256Time:64
Test accuracy:88.57142857142857Time:64
Test Loss:0.009018084582160501Time:64
Training accuracy:100.0Time:65
Training Loss:8.622001290420529e-05Time:65
Test accuracy:88.57142857142857Time:65
Test Loss:0.012545612078754842Time:65
Training accuracy:100.0Time:66
Training Loss:7.899728166383145e-05Time:66
Test accuracy:88.15126050420169Time:66
Test Loss:0.019589392077021237Time:66
Training accuracy:100.0Time:67
Training Loss:8.22302603477326e-05Time:67
Test accuracy:87.98319327731092Time:67
Test Loss:0.005477149145943778Time:67
Training accuracy:100.0Time:68
Training Loss:6.474603558222805e-05Time:68
Test accuracy:88.40336134453781Time:68
Test Loss:0.01021453713168617Time:68
Training accuracy:100.0Time:69
Training Loss:6.90382918789252e-05Time:69
Test accuracy:88.23529411764706Time:69
Test Loss:0.003940355877916352Time:69
Training accuracy:100.0Time:70
Training Loss:5.430255669698951e-05Time:70
Test accuracy:88.90756302521008Time:70
Test Loss:0.006975255693708147Time:70
Training accuracy:100.0Time:71
Training Loss:4.693369927808698e-05Time:71
Test accuracy:88.65546218487395Time:71
Test Loss:0.014634101931788341Time:71
Training accuracy:100.0Time:72
Training Loss:4.736528797022953e-05Time:72
Test accuracy:88.4873949579832Time:72
Test Loss:0.010839457471831506Time:72
Training accuracy:100.0Time:73
Training Loss:4.392883977219845e-05Time:73
Test accuracy:88.40336134453781Time:73
Test Loss:0.013523805441976596Time:73
Training accuracy:100.0Time:74
Training Loss:4.235677372591134e-05Time:74
Test accuracy:88.73949579831933Time:74
Test Loss:0.01167738297406365Time:74
Training accuracy:100.0Time:75
Training Loss:3.764569218453613e-05Time:75
Test accuracy:88.73949579831933Time:75
Test Loss:0.010060768768566998Time:75
Training accuracy:100.0Time:76
Training Loss:3.56889031662152e-05Time:76
Test accuracy:89.15966386554622Time:76
Test Loss:0.006532594536532875Time:76
Training accuracy:100.0Time:77
Training Loss:6.784660575192792e-05Time:77
Test accuracy:87.89915966386555Time:77
Test Loss:0.023467046272854845Time:77
Training accuracy:100.0Time:78
Training Loss:0.0001773321437564605Time:78
Test accuracy:87.47899159663865Time:78
Test Loss:0.010086474699132583Time:78
Training accuracy:100.0Time:79
Training Loss:0.00013472960432334545Time:79
Test accuracy:88.31932773109244Time:79
Test Loss:0.007973869708405823Time:79
Training accuracy:100.0Time:80
Training Loss:9.821982652345644e-05Time:80
Test accuracy:88.40336134453781Time:80
Test Loss:0.01875671098212234Time:80
Training accuracy:100.0Time:81
Training Loss:8.46343369334971e-05Time:81
Test accuracy:88.90756302521008Time:81
Test Loss:0.015127053781717765Time:81
Training accuracy:100.0Time:82
Training Loss:9.076636039253041e-05Time:82
Test accuracy:88.57142857142857Time:82
Test Loss:0.010120549722879875Time:82
Training accuracy:100.0Time:83
Training Loss:8.962877415118862e-05Time:83
Test accuracy:87.98319327731092Time:83
Test Loss:0.014434053116485853Time:83
Training accuracy:100.0Time:84
Training Loss:8.387757589869177e-05Time:84
Test accuracy:88.40336134453781Time:84
Test Loss:0.010603133770598083Time:84
Training accuracy:100.0Time:85
Training Loss:8.329204953545752e-05Time:85
Test accuracy:87.81512605042016Time:85
Test Loss:0.014373710375873983Time:85
Training accuracy:100.0Time:86
Training Loss:8.222798431128619e-05Time:86
Test accuracy:87.73109243697479Time:86
Test Loss:0.007002490708807937Time:86
Training accuracy:100.0Time:87
Training Loss:7.163682033162997e-05Time:87
Test accuracy:88.31932773109244Time:87
Test Loss:0.013394488807485885Time:87
Training accuracy:100.0Time:88
Training Loss:5.493895888036236e-05Time:88
Test accuracy:88.65546218487395Time:88
Test Loss:0.008043591315005006Time:88
Training accuracy:100.0Time:89
Training Loss:5.275518106266644e-05Time:89
Test accuracy:89.15966386554622Time:89
Test Loss:0.009543220936751166Time:89
Training accuracy:100.0Time:90
Training Loss:5.127226572030514e-05Time:90
Test accuracy:89.07563025210084Time:90
Test Loss:0.004155004725736731Time:90
Training accuracy:100.0Time:91
Training Loss:4.35168582014957e-05Time:91
Test accuracy:88.82352941176471Time:91
Test Loss:0.004902384060771525Time:91
Training accuracy:100.0Time:92
Training Loss:5.5310202486045737e-05Time:92
Test accuracy:88.15126050420169Time:92
Test Loss:0.00784533765135693Time:92
Training accuracy:100.0Time:93
Training Loss:3.939590567247903e-05Time:93
Test accuracy:89.41176470588235Time:93
Test Loss:0.01564837864467076Time:93
Training accuracy:100.0Time:94
Training Loss:4.022176031002384e-05Time:94
Test accuracy:88.90756302521008Time:94
Test Loss:0.012630563623764936Time:94
Training accuracy:100.0Time:95
Training Loss:3.87003849639389e-05Time:95
Test accuracy:89.15966386554622Time:95
Test Loss:0.01879198571213153Time:95
Training accuracy:100.0Time:96
Training Loss:3.207867898983078e-05Time:96
Test accuracy:89.83193277310924Time:96
Test Loss:0.010905807559229746Time:96
Training accuracy:100.0Time:97
Training Loss:3.2668817683528905e-05Time:97
Test accuracy:88.90756302521008Time:97
Test Loss:0.015843771285369616Time:97
Training accuracy:100.0Time:98
Training Loss:3.115596162265759e-05Time:98
Test accuracy:89.91596638655462Time:98
Test Loss:0.005845859671841149Time:98
Training accuracy:100.0Time:99
Training Loss:2.853651444585572e-05Time:99
Test accuracy:89.91596638655462Time:99
Test Loss:0.019189603789513853Time:99
