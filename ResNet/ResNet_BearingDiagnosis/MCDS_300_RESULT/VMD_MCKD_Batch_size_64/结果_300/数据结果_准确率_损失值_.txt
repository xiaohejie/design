D:\python\anaconda\envs\py310\python.exe D:/0_大型机械设备故障检测/参考代码/代码/0/ResNet_BearingDiagnosis/main.py
ResNet(
  (conv1): Conv1d(1, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (pool): AdaptiveAvgPool1d(output_size=1)
  (ACTClassifier): Sequential(
    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): AdaptiveAvgPool1d(output_size=1)
  )
  (act_fc): Linear(in_features=512, out_features=5, bias=True)
)
[9636, 1071]
using cpu device.
D:\python\anaconda\envs\py310\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
D:\python\anaconda\envs\py310\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Training accuracy:35.066417600664174Time:0
Training Loss:1.4968771223905126Time:0
Test accuracy:33.42670401493931Time:0
Test Loss:0.05894029262909591Time:0
Training accuracy:36.104192611041924Time:1
Training Loss:1.7954473123356434Time:1
Test accuracy:34.64052287581699Time:1
Test Loss:0.07442652455676281Time:1
Training accuracy:40.41095890410959Time:2
Training Loss:1.8568071014606988Time:2
Test accuracy:37.81512605042017Time:2
Test Loss:0.08317481146918403Time:2
Training accuracy:70.55832295558324Time:3
Training Loss:0.7530797180074436Time:3
Test accuracy:59.57049486461251Time:3
Test Loss:0.050526028587704615Time:3
Training accuracy:53.40390203403902Time:4
Training Loss:1.6078884066165657Time:4
Test accuracy:48.36601307189542Time:4
Test Loss:0.09951002902788719Time:4
Training accuracy:86.50892486508926Time:5
Training Loss:0.3820802957598923Time:5
Test accuracy:70.58823529411765Time:5
Test Loss:0.04128212666088571Time:5
Training accuracy:82.16064757160648Time:6
Training Loss:0.4998429574724944Time:6
Test accuracy:66.29318394024277Time:6
Test Loss:0.039266655758983283Time:6
Training accuracy:95.25736820257369Time:7
Training Loss:0.14864434370513574Time:7
Test accuracy:83.0999066293184Time:7
Test Loss:0.026174951334293484Time:7
Training accuracy:93.47239518472395Time:8
Training Loss:0.1963646887446301Time:8
Test accuracy:80.20541549953315Time:8
Test Loss:0.01883027355432733Time:8
Training accuracy:90.53549190535492Time:9
Training Loss:0.24848232288091399Time:9
Test accuracy:77.59103641456582Time:9
Test Loss:0.03250735413794424Time:9
Training accuracy:96.96969696969697Time:10
Training Loss:0.08749318167400241Time:10
Test accuracy:85.24743230625583Time:10
Test Loss:0.011768058791102704Time:10
Training accuracy:88.85429638854296Time:11
Training Loss:0.2965277527911676Time:11
Test accuracy:76.37721755368814Time:11
Test Loss:0.047986807943392204Time:11
Training accuracy:61.88252386882524Time:12
Training Loss:2.5841492996912567Time:12
Test accuracy:51.82072829131653Time:12
Test Loss:0.1491935722856851Time:12
Training accuracy:74.18015774180158Time:13
Training Loss:1.0701286918446948Time:13
Test accuracy:60.59757236227824Time:13
Test Loss:0.12808672052805498Time:13
Training accuracy:95.19510170195102Time:14
Training Loss:0.12813216669275435Time:14
Test accuracy:81.04575163398692Time:14
Test Loss:0.025903726714888428Time:14
Training accuracy:95.68285595682856Time:15
Training Loss:0.11077076702654337Time:15
Test accuracy:81.69934640522875Time:15
Test Loss:0.01886694237631576Time:15
Training accuracy:91.86384391863844Time:16
Training Loss:0.34734171933284586Time:16
Test accuracy:81.04575163398692Time:16
Test Loss:0.057838073075095926Time:16
Training accuracy:98.65089248650892Time:17
Training Loss:0.0395126719292193Time:17
Test accuracy:87.6750700280112Time:17
Test Loss:0.02219148666139633Time:17
Training accuracy:89.87131589871316Time:18
Training Loss:0.37916266626221057Time:18
Test accuracy:79.27170868347339Time:18
Test Loss:0.039943118055327596Time:18
Training accuracy:99.65753424657534Time:19
Training Loss:0.010551473992575547Time:19
Test accuracy:94.49112978524744Time:19
Test Loss:0.002892630886074319Time:19
Training accuracy:99.69904524699045Time:20
Training Loss:0.009277795505044605Time:20
Test accuracy:95.7983193277311Time:20
Test Loss:0.004001830249718703Time:20
Training accuracy:99.64715649647157Time:21
Training Loss:0.008725160676228241Time:21
Test accuracy:95.89169000933707Time:21
Test Loss:0.005373793155873189Time:21
Training accuracy:99.76131174761312Time:22
Training Loss:0.006629189598246877Time:22
Test accuracy:96.07843137254902Time:22
Test Loss:0.004568318136377272Time:22
Training accuracy:99.71980074719801Time:23
Training Loss:0.007762581398985095Time:23
Test accuracy:94.58450046685341Time:23
Test Loss:0.0026452423366400595Time:23
Training accuracy:99.69904524699045Time:24
Training Loss:0.008367851458492987Time:24
Test accuracy:94.77124183006536Time:24
Test Loss:0.006469573404719961Time:24
Training accuracy:99.69904524699045Time:25
Training Loss:0.007547719739671316Time:25
Test accuracy:96.171802054155Time:25
Test Loss:0.0012348347128717616Time:25
Training accuracy:99.73017849730178Time:26
Training Loss:0.011780433105471076Time:26
Test accuracy:93.74416433239962Time:26
Test Loss:0.004517739560423779Time:26
Training accuracy:99.74055624740556Time:27
Training Loss:0.010230098202694694Time:27
Test accuracy:93.55742296918767Time:27
Test Loss:0.00917952579387875Time:27
Training accuracy:95.80738895807389Time:28
Training Loss:0.11013026722935336Time:28
Test accuracy:82.3529411764706Time:28
Test Loss:0.031600432124347134Time:28
Training accuracy:99.3046907430469Time:29
Training Loss:0.02262859198741457Time:29
Test accuracy:90.66293183940243Time:29
Test Loss:0.014157527635077468Time:29
Training accuracy:99.88584474885845Time:30
Training Loss:0.006088097739056984Time:30
Test accuracy:94.21101774042951Time:30
Test Loss:0.007391593925981851Time:30
Training accuracy:99.22166874221669Time:31
Training Loss:0.02345448473739817Time:31
Test accuracy:89.91596638655462Time:31
Test Loss:0.024577398148794023Time:31
Training accuracy:99.813200498132Time:32
Training Loss:0.005808649275176638Time:32
Test accuracy:93.8375350140056Time:32
Test Loss:0.004977533018110401Time:32
Training accuracy:99.56413449564134Time:33
Training Loss:0.013496387823364604Time:33
Test accuracy:94.30438842203549Time:33
Test Loss:0.010824165201765927Time:33
Training accuracy:95.83852220838523Time:34
Training Loss:0.11171368139940162Time:34
Test accuracy:83.8468720821662Time:34
Test Loss:0.03770817917824682Time:34
Training accuracy:99.46035699460357Time:35
Training Loss:0.014191680899428821Time:35
Test accuracy:92.53034547152194Time:35
Test Loss:0.003583635380065519Time:35
Training accuracy:99.96886674968867Time:36
Training Loss:0.002699299322720733Time:36
Test accuracy:95.42483660130719Time:36
Test Loss:0.0016672070286854975Time:36
Training accuracy:100.0Time:37
Training Loss:0.0009056159622109762Time:37
Test accuracy:95.70494864612512Time:37
Test Loss:0.00291892972424362Time:37
Training accuracy:99.92735574927356Time:38
Training Loss:0.0033282821170866625Time:38
Test accuracy:93.55742296918767Time:38
Test Loss:0.006469020433897843Time:38
Training accuracy:100.0Time:39
Training Loss:0.00035321700398107753Time:39
Test accuracy:96.45191409897292Time:39
Test Loss:0.005849675304081594Time:39
Training accuracy:99.97924449979244Time:40
Training Loss:0.0015440077413431759Time:40
Test accuracy:94.86461251167134Time:40
Test Loss:0.006308763968844374Time:40
Training accuracy:100.0Time:41
Training Loss:0.00039497736702070427Time:41
Test accuracy:96.45191409897292Time:41
Test Loss:0.004802122837355157Time:41
Training accuracy:100.0Time:42
Training Loss:0.0002971228325972237Time:42
Test accuracy:95.7983193277311Time:42
Test Loss:0.006822832269606247Time:42
Training accuracy:99.95848899958489Time:43
Training Loss:0.004221414733135314Time:43
Test accuracy:93.4640522875817Time:43
Test Loss:0.004121739879932279Time:43
Training accuracy:100.0Time:44
Training Loss:0.0008342663752960467Time:44
Test accuracy:94.77124183006536Time:44
Test Loss:0.0024926321847098215Time:44
Training accuracy:99.88584474885845Time:45
Training Loss:0.0020713854618497145Time:45
Test accuracy:96.63865546218487Time:45
Test Loss:0.008061310156386774Time:45
Training accuracy:100.0Time:46
Training Loss:0.00015924439866319236Time:46
Test accuracy:96.73202614379085Time:46
Test Loss:0.005023947839532135Time:46
Training accuracy:100.0Time:47
Training Loss:8.872186520501071e-05Time:47
Test accuracy:97.01213818860877Time:47
Test Loss:0.010146142833150512Time:47
Training accuracy:100.0Time:48
Training Loss:0.0007032006115417954Time:48
Test accuracy:96.35854341736695Time:48
Test Loss:0.005054472096048706Time:48
Training accuracy:100.0Time:49
Training Loss:0.00018567900974017398Time:49
Test accuracy:97.10550887021475Time:49
Test Loss:0.00607513691308229Time:49
Training accuracy:100.0Time:50
Training Loss:0.00013764738201887814Time:50
Test accuracy:96.82539682539682Time:50
Test Loss:0.0002928971409463749Time:50
Training accuracy:96.71025321710253Time:51
Training Loss:0.10562305682214675Time:51
Test accuracy:84.40709617180205Time:51
Test Loss:0.028479021359113305Time:51
Training accuracy:100.0Time:52
Training Loss:0.0005891974680508449Time:52
Test accuracy:95.89169000933707Time:52
Test Loss:0.003408996330923727Time:52
Training accuracy:99.56413449564134Time:53
Training Loss:0.012463147489291384Time:53
Test accuracy:92.15686274509804Time:53
Test Loss:0.014777594031183438Time:53
Training accuracy:100.0Time:54
Training Loss:0.00017396116152708447Time:54
Test accuracy:96.9187675070028Time:54
Test Loss:0.012481775826989325Time:54
Training accuracy:100.0Time:55
Training Loss:0.0004073478681243718Time:55
Test accuracy:96.63865546218487Time:55
Test Loss:0.007895072523841893Time:55
Training accuracy:95.39227895392278Time:56
Training Loss:0.11990578583336906Time:56
Test accuracy:82.25957049486462Time:56
Test Loss:0.03810090422073777Time:56
Training accuracy:100.0Time:57
Training Loss:0.0010827920245835554Time:57
Test accuracy:95.51820728291317Time:57
Test Loss:0.0077024596968507456Time:57
Training accuracy:99.98962224989623Time:58
Training Loss:0.0010524401633067372Time:58
Test accuracy:96.26517273576097Time:58
Test Loss:0.006682155067735916Time:58
Training accuracy:100.0Time:59
Training Loss:0.0001888182455677293Time:59
Test accuracy:96.63865546218487Time:59
Test Loss:0.006537721493219684Time:59
Training accuracy:100.0Time:60
Training Loss:0.00012552800448215114Time:60
Test accuracy:96.5452847805789Time:60
Test Loss:0.003994382507438197Time:60
Training accuracy:100.0Time:61
Training Loss:0.0003708216724067736Time:61
Test accuracy:95.33146591970122Time:61
Test Loss:0.004755313545604603Time:61
Training accuracy:100.0Time:62
Training Loss:0.00010559053575411677Time:62
Test accuracy:96.26517273576097Time:62
Test Loss:0.00032604725754895465Time:62
Training accuracy:100.0Time:63
Training Loss:7.274992597491769e-05Time:63
Test accuracy:97.10550887021475Time:63
Test Loss:0.006750000847710503Time:63
Training accuracy:100.0Time:64
Training Loss:4.7034963465202175e-05Time:64
Test accuracy:97.38562091503267Time:64
Test Loss:0.002351101484396656Time:64
Training accuracy:100.0Time:65
Training Loss:6.079073869368087e-05Time:65
Test accuracy:97.19887955182072Time:65
Test Loss:0.00045400348698057714Time:65
Training accuracy:100.0Time:66
Training Loss:3.91772670196839e-05Time:66
Test accuracy:96.82539682539682Time:66
Test Loss:0.004322898822004388Time:66
Training accuracy:100.0Time:67
Training Loss:3.7322341166148656e-05Time:67
Test accuracy:97.38562091503267Time:67
Test Loss:0.005151695675320095Time:67
Training accuracy:100.0Time:68
Training Loss:5.530507844339649e-05Time:68
Test accuracy:97.38562091503267Time:68
Test Loss:0.0038690896483919088Time:68
Training accuracy:100.0Time:69
Training Loss:4.111988363256342e-05Time:69
Test accuracy:97.10550887021475Time:69
Test Loss:0.0023394570408526365Time:69
Training accuracy:100.0Time:70
Training Loss:2.8313337599680997e-05Time:70
Test accuracy:97.2922502334267Time:70
Test Loss:0.0030806685696129037Time:70
Training accuracy:100.0Time:71
Training Loss:0.0001268856671361207Time:71
Test accuracy:96.07843137254902Time:71
Test Loss:0.007876986549014137Time:71
Training accuracy:100.0Time:72
Training Loss:3.826135894938555e-05Time:72
Test accuracy:96.73202614379085Time:72
Test Loss:0.00029734954112718085Time:72
Training accuracy:100.0Time:73
Training Loss:2.6633285642202383e-05Time:73
Test accuracy:97.2922502334267Time:73
Test Loss:0.006372054640541113Time:73
Training accuracy:100.0Time:74
Training Loss:2.2903525888189733e-05Time:74
Test accuracy:97.47899159663865Time:74
Test Loss:0.002522852574409891Time:74
Training accuracy:100.0Time:75
Training Loss:3.583005693824842e-05Time:75
Test accuracy:97.2922502334267Time:75
Test Loss:0.007112134849769172Time:75
Training accuracy:100.0Time:76
Training Loss:4.730761403250966e-05Time:76
Test accuracy:97.10550887021475Time:76
Test Loss:0.010299730701606814Time:76
Training accuracy:100.0Time:77
Training Loss:2.4481605061100068e-05Time:77
Test accuracy:97.01213818860877Time:77
Test Loss:0.00016151030524438168Time:77
Training accuracy:100.0Time:78
Training Loss:2.026136503066313e-05Time:78
Test accuracy:97.47899159663865Time:78
Test Loss:0.0010129523878337956Time:78
Training accuracy:100.0Time:79
Training Loss:1.878335085542735e-05Time:79
Test accuracy:97.6657329598506Time:79
Test Loss:0.003606390663666997Time:79
Training accuracy:100.0Time:80
Training Loss:2.2771296286079824e-05Time:80
Test accuracy:97.57236227824463Time:80
Test Loss:0.0025171294154461917Time:80
Training accuracy:100.0Time:81
Training Loss:2.197349006018463e-05Time:81
Test accuracy:97.38562091503267Time:81
Test Loss:0.002024157485819442Time:81
Training accuracy:100.0Time:82
Training Loss:1.883530388390023e-05Time:82
Test accuracy:97.47899159663865Time:82
Test Loss:0.005886132643670261Time:82
Training accuracy:100.0Time:83
Training Loss:7.766063482030988e-05Time:83
Test accuracy:96.9187675070028Time:83
Test Loss:0.0048144097421683515Time:83
Training accuracy:100.0Time:84
Training Loss:1.811706293203229e-05Time:84
Test accuracy:97.47899159663865Time:84
Test Loss:0.001090192438618921Time:84
Training accuracy:100.0Time:85
Training Loss:2.1663385498310966e-05Time:85
Test accuracy:97.57236227824463Time:85
Test Loss:0.00242114467781131Time:85
Training accuracy:100.0Time:86
Training Loss:0.0001588346561470842Time:86
Test accuracy:97.38562091503267Time:86
Test Loss:0.0029796828297562515Time:86
Training accuracy:100.0Time:87
Training Loss:4.4246280104159264e-05Time:87
Test accuracy:97.10550887021475Time:87
Test Loss:0.002341037148298447Time:87
Training accuracy:100.0Time:88
Training Loss:2.5249822490858073e-05Time:88
Test accuracy:97.94584500466853Time:88
Test Loss:0.0014754249936058408Time:88
Training accuracy:100.0Time:89
Training Loss:2.3971068528983894e-05Time:89
Test accuracy:97.6657329598506Time:89
Test Loss:0.0010366474324359056Time:89
Training accuracy:100.0Time:90
Training Loss:2.0356600369090362e-05Time:90
Test accuracy:96.73202614379085Time:90
Test Loss:0.001900842766356624Time:90
Training accuracy:100.0Time:91
Training Loss:2.221356170876713e-05Time:91
Test accuracy:96.82539682539682Time:91
Test Loss:0.002761111539952895Time:91
Training accuracy:100.0Time:92
Training Loss:1.7751563757858264e-05Time:92
Test accuracy:97.19887955182072Time:92
Test Loss:0.0038624250588296842Time:92
Training accuracy:100.0Time:93
Training Loss:1.7354809057146108e-05Time:93
Test accuracy:97.57236227824463Time:93
Test Loss:0.006281826899053892Time:93
Training accuracy:100.0Time:94
Training Loss:1.8307295069833014e-05Time:94
Test accuracy:97.6657329598506Time:94
Test Loss:0.007544009959330412Time:94
Training accuracy:100.0Time:95
Training Loss:2.4516082338781176e-05Time:95
Test accuracy:97.85247432306255Time:95
Test Loss:0.0013421169516085244Time:95
Training accuracy:100.0Time:96
Training Loss:2.333604843239155e-05Time:96
Test accuracy:97.57236227824463Time:96
Test Loss:0.00100775426175414Time:96
Training accuracy:100.0Time:97
Training Loss:1.5560933306918877e-05Time:97
Test accuracy:97.47899159663865Time:97
Test Loss:0.006612534171281631Time:97
Training accuracy:100.0Time:98
Training Loss:9.312386363716225e-06Time:98
Test accuracy:97.19887955182072Time:98
Test Loss:0.0014249426977975027Time:98
Training accuracy:100.0Time:99
Training Loss:1.6929101809415553e-05Time:99
Test accuracy:97.2922502334267Time:99
Test Loss:0.004573281962219295Time:99
