D:\python\anaconda\envs\py310\python.exe D:/0_大型机械设备故障检测/参考代码/代码/0/ResNet_BearingDiagnosis/main.py
ResNet(
  (conv1): Conv1d(1, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (pool): AdaptiveAvgPool1d(output_size=1)
  (ACTClassifier): Sequential(
    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): AdaptiveAvgPool1d(output_size=1)
  )
  (act_fc): Linear(in_features=512, out_features=5, bias=True)
)
[9636, 1071]
using cpu device.
D:\python\anaconda\envs\py310\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
D:\python\anaconda\envs\py310\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Training accuracy:19.115815691158158Time:0
Training Loss:1.842230094919169Time:0
Test accuracy:16.99346405228758Time:0
Test Loss:0.07779954327922575Time:0
Training accuracy:43.16106268161062Time:1
Training Loss:1.4371980545975054Time:1
Test accuracy:37.62838468720822Time:1
Test Loss:0.07157328772166419Time:1
Training accuracy:39.33167289331673Time:2
Training Loss:1.5839147563790226Time:2
Test accuracy:36.60130718954248Time:2
Test Loss:0.07682734043324362Time:2
Training accuracy:67.36197592361975Time:3
Training Loss:0.9267678468640091Time:3
Test accuracy:51.82072829131653Time:3
Test Loss:0.06595898654057977Time:3
Training accuracy:47.53009547530095Time:4
Training Loss:2.3712764136669495Time:4
Test accuracy:35.3874883286648Time:4
Test Loss:0.127179399591868Time:4
Training accuracy:76.32835201328352Time:5
Training Loss:0.6057545086712993Time:5
Test accuracy:59.47712418300654Time:5
Test Loss:0.04627447546808437Time:5
Training accuracy:84.35035284350353Time:6
Training Loss:0.3950758839405736Time:6
Test accuracy:65.91970121381885Time:6
Test Loss:0.058174763740945594Time:6
Training accuracy:82.18140307181403Time:7
Training Loss:0.47593313571871343Time:7
Test accuracy:57.983193277310924Time:7
Test Loss:0.038163791517583597Time:7
Training accuracy:84.79659609796596Time:8
Training Loss:0.4222334836617007Time:8
Test accuracy:61.99813258636788Time:8
Test Loss:0.04313308829798195Time:8
Training accuracy:97.16687422166875Time:9
Training Loss:0.10835178450659233Time:9
Test accuracy:74.78991596638656Time:9
Test Loss:0.024090726836388854Time:9
Training accuracy:97.0008302200083Time:10
Training Loss:0.10242134359873593Time:10
Test accuracy:73.66946778711484Time:10
Test Loss:0.04054242088681176Time:10
Training accuracy:97.17725197177252Time:11
Training Loss:0.08694750439234916Time:11
Test accuracy:75.35014005602241Time:11
Test Loss:0.02910923000588582Time:11
Training accuracy:91.1892901618929Time:12
Training Loss:0.22053666864999255Time:12
Test accuracy:70.12138188608778Time:12
Test Loss:0.060175549305008465Time:12
Training accuracy:99.1282689912827Time:13
Training Loss:0.027323904050217965Time:13
Test accuracy:83.38001867413632Time:13
Test Loss:0.01795938814164989Time:13
Training accuracy:98.2461602324616Time:14
Training Loss:0.07237408105740165Time:14
Test accuracy:74.32306255835668Time:14
Test Loss:0.03193990812470822Time:14
Training accuracy:97.26027397260275Time:15
Training Loss:0.08106663345597799Time:15
Test accuracy:74.69654528478058Time:15
Test Loss:0.018463376968625992Time:15
Training accuracy:99.43960149439602Time:16
Training Loss:0.019069440393786354Time:16
Test accuracy:83.28664799253035Time:16
Test Loss:0.020425865964061405Time:16
Training accuracy:96.16023246160232Time:17
Training Loss:0.1112290600267571Time:17
Test accuracy:78.33800186741364Time:17
Test Loss:0.019699821507786056Time:17
Training accuracy:99.32544624325446Time:18
Training Loss:0.02983294870903899Time:18
Test accuracy:80.0186741363212Time:18
Test Loss:0.02015190231365984Time:18
Training accuracy:99.6782897467829Time:19
Training Loss:0.010220508756492582Time:19
Test accuracy:88.14192343604108Time:19
Test Loss:0.008795002706689772Time:19
Training accuracy:99.75093399750934Time:20
Training Loss:0.00913633129549019Time:20
Test accuracy:89.26237161531279Time:20
Test Loss:0.013321461575149265Time:20
Training accuracy:99.77168949771689Time:21
Training Loss:0.007383878571288672Time:21
Test accuracy:88.60877684407096Time:21
Test Loss:0.021171963404095363Time:21
Training accuracy:99.76131174761312Time:22
Training Loss:0.007457462953996638Time:22
Test accuracy:91.03641456582633Time:22
Test Loss:0.008199152158421963Time:22
Training accuracy:99.73017849730178Time:23
Training Loss:0.007672351720441719Time:23
Test accuracy:90.47619047619048Time:23
Test Loss:0.014032890148857394Time:23
Training accuracy:99.70942299709424Time:24
Training Loss:0.007204437297457677Time:24
Test accuracy:90.10270774976658Time:24
Test Loss:0.016716710437023115Time:24
Training accuracy:99.82357824823578Time:25
Training Loss:0.007205186134158649Time:25
Test accuracy:86.83473389355743Time:25
Test Loss:0.014375527254562306Time:25
Training accuracy:99.68866749688668Time:26
Training Loss:0.008675006982565372Time:26
Test accuracy:87.6750700280112Time:26
Test Loss:0.011982198300259232Time:26
Training accuracy:99.70942299709424Time:27
Training Loss:0.008554188379203694Time:27
Test accuracy:85.71428571428571Time:27
Test Loss:0.014507955307163556Time:27
Training accuracy:99.77168949771689Time:28
Training Loss:0.005223381585117171Time:28
Test accuracy:90.94304388422036Time:28
Test Loss:0.008081574177319039Time:28
Training accuracy:99.96886674968867Time:29
Training Loss:0.011256552097608362Time:29
Test accuracy:85.80765639589168Time:29
Test Loss:0.021807655455574157Time:29
Training accuracy:99.73017849730178Time:30
Training Loss:0.007268946787559699Time:30
Test accuracy:88.60877684407096Time:30
Test Loss:0.008500695785109291Time:30
Training accuracy:99.98962224989623Time:31
Training Loss:0.0033245463826569494Time:31
Test accuracy:89.63585434173669Time:31
Test Loss:0.007583852352993606Time:31
Training accuracy:99.62640099626401Time:32
Training Loss:0.01000929831137866Time:32
Test accuracy:89.07563025210084Time:32
Test Loss:0.013309640822067759Time:32
Training accuracy:96.44043171440431Time:33
Training Loss:0.12270854471035644Time:33
Test accuracy:75.91036414565826Time:33
Test Loss:0.024456230754834486Time:33
Training accuracy:100.0Time:34
Training Loss:0.0026871387384006123Time:34
Test accuracy:88.88888888888889Time:34
Test Loss:0.010767942939708435Time:34
Training accuracy:77.09630552096306Time:35
Training Loss:0.7610193805211607Time:35
Test accuracy:55.27544351073763Time:35
Test Loss:0.08716224221622243Time:35
Training accuracy:99.71980074719801Time:36
Training Loss:0.008765687962670007Time:36
Test accuracy:88.51540616246498Time:36
Test Loss:0.017834404269520307Time:36
Training accuracy:99.77168949771689Time:37
Training Loss:0.00817699275134559Time:37
Test accuracy:86.46125116713353Time:37
Test Loss:0.018056792927945917Time:37
Training accuracy:99.89622249896223Time:38
Training Loss:0.004651376096885102Time:38
Test accuracy:88.23529411764706Time:38
Test Loss:0.014488126717361749Time:38
Training accuracy:99.98962224989623Time:39
Training Loss:0.004161966796817499Time:39
Test accuracy:89.16900093370681Time:39
Test Loss:0.00644479301018096Time:39
Training accuracy:99.97924449979244Time:40
Training Loss:0.0030149317312878955Time:40
Test accuracy:89.91596638655462Time:40
Test Loss:0.007447175062448482Time:40
Training accuracy:99.88584474885845Time:41
Training Loss:0.002789350289924108Time:41
Test accuracy:90.94304388422036Time:41
Test Loss:0.010952720677707932Time:41
Training accuracy:99.86508924865089Time:42
Training Loss:0.0028619149047610743Time:42
Test accuracy:91.40989729225024Time:42
Test Loss:0.006852736771384986Time:42
Training accuracy:100.0Time:43
Training Loss:0.0011904690516729877Time:43
Test accuracy:90.10270774976658Time:43
Test Loss:0.005942468438384469Time:43
Training accuracy:100.0Time:44
Training Loss:0.001009175066703574Time:44
Test accuracy:91.59663865546219Time:44
Test Loss:0.012460690809119872Time:44
Training accuracy:100.0Time:45
Training Loss:0.0006966459362962097Time:45
Test accuracy:91.22315592903828Time:45
Test Loss:0.017388497859267407Time:45
Training accuracy:100.0Time:46
Training Loss:0.0009385305323439695Time:46
Test accuracy:91.22315592903828Time:46
Test Loss:0.0058711890746899345Time:46
Training accuracy:99.74055624740556Time:47
Training Loss:0.006698048356170474Time:47
Test accuracy:86.1811391223156Time:47
Test Loss:0.015869420226993794Time:47
Training accuracy:100.0Time:48
Training Loss:0.000776682199230638Time:48
Test accuracy:90.75630252100841Time:48
Test Loss:0.013403779429659233Time:48
Training accuracy:99.98962224989623Time:49
Training Loss:0.0012207933859694742Time:49
Test accuracy:92.25023342670401Time:49
Test Loss:0.009667962873015417Time:49
Training accuracy:100.0Time:50
Training Loss:0.0005264613291634507Time:50
Test accuracy:90.75630252100841Time:50
Test Loss:0.011420169798265985Time:50
Training accuracy:100.0Time:51
Training Loss:0.00036184371195056224Time:51
Test accuracy:91.59663865546219Time:51
Test Loss:0.007212493711270316Time:51
Training accuracy:100.0Time:52
Training Loss:0.0004583340459655941Time:52
Test accuracy:91.97012138188609Time:52
Test Loss:0.008822312875956046Time:52
Training accuracy:100.0Time:53
Training Loss:0.0006230804321521197Time:53
Test accuracy:90.19607843137256Time:53
Test Loss:0.01477828858390687Time:53
Training accuracy:100.0Time:54
Training Loss:0.0011878937222651175Time:54
Test accuracy:91.12978524743231Time:54
Test Loss:0.014080287139066238Time:54
Training accuracy:100.0Time:55
Training Loss:0.0004548138215706439Time:55
Test accuracy:91.22315592903828Time:55
Test Loss:0.00565467740084722Time:55
Training accuracy:100.0Time:56
Training Loss:0.00044238102348229856Time:56
Test accuracy:91.31652661064426Time:56
Test Loss:0.017101854169402134Time:56
Training accuracy:99.97924449979244Time:57
Training Loss:0.0012119111373800986Time:57
Test accuracy:90.75630252100841Time:57
Test Loss:0.008878982145022722Time:57
Training accuracy:100.0Time:58
Training Loss:0.0003456116811325561Time:58
Test accuracy:91.78338001867414Time:58
Test Loss:0.012104700482080854Time:58
Training accuracy:100.0Time:59
Training Loss:0.00024168857115434135Time:59
Test accuracy:91.12978524743231Time:59
Test Loss:0.009939411886377272Time:59
Training accuracy:100.0Time:60
Training Loss:0.00024798572053394413Time:60
Test accuracy:91.87675070028011Time:60
Test Loss:0.012055429980423159Time:60
Training accuracy:100.0Time:61
Training Loss:0.00023006832350050082Time:61
Test accuracy:92.25023342670401Time:61
Test Loss:0.007271877078671638Time:61
Training accuracy:100.0Time:62
Training Loss:0.00020565323296960656Time:62
Test accuracy:91.97012138188609Time:62
Test Loss:0.005372476177055295Time:62
Training accuracy:100.0Time:63
Training Loss:0.00018831598173750386Time:63
Test accuracy:91.40989729225024Time:63
Test Loss:0.012702331044315512Time:63
Training accuracy:100.0Time:64
Training Loss:0.00017887222723267593Time:64
Test accuracy:91.78338001867414Time:64
Test Loss:0.008476915368401592Time:64
Training accuracy:100.0Time:65
Training Loss:0.0002035542555352856Time:65
Test accuracy:91.69000933706816Time:65
Test Loss:0.010627775966954165Time:65
Training accuracy:100.0Time:66
Training Loss:0.00038525125981397825Time:66
Test accuracy:92.90382819794584Time:66
Test Loss:0.0061786760246497685Time:66
Training accuracy:100.0Time:67
Training Loss:0.0001676053809527433Time:67
Test accuracy:91.87675070028011Time:67
Test Loss:0.0046851445758153525Time:67
Training accuracy:100.0Time:68
Training Loss:0.0001932048605505227Time:68
Test accuracy:91.59663865546219Time:68
Test Loss:0.01638006963649718Time:68
Training accuracy:100.0Time:69
Training Loss:0.00015824068429110122Time:69
Test accuracy:91.97012138188609Time:69
Test Loss:0.0109920840080824Time:69
Training accuracy:100.0Time:70
Training Loss:0.00015399590823350913Time:70
Test accuracy:92.15686274509804Time:70
Test Loss:0.00814579091931369Time:70
Training accuracy:100.0Time:71
Training Loss:0.0001651772741350508Time:71
Test accuracy:91.87675070028011Time:71
Test Loss:0.007203304689694074Time:71
Training accuracy:100.0Time:72
Training Loss:0.00015156156657555135Time:72
Test accuracy:92.43697478991596Time:72
Test Loss:0.006098682250406673Time:72
Training accuracy:100.0Time:73
Training Loss:0.00013565822593765715Time:73
Test accuracy:91.69000933706816Time:73
Test Loss:0.005787977206161599Time:73
Training accuracy:100.0Time:74
Training Loss:0.00016220104017543527Time:74
Test accuracy:91.69000933706816Time:74
Test Loss:0.00787535524056628Time:74
Training accuracy:100.0Time:75
Training Loss:0.00011963273953157757Time:75
Test accuracy:92.25023342670401Time:75
Test Loss:0.012096627642349258Time:75
Training accuracy:100.0Time:76
Training Loss:0.0001250467078656657Time:76
Test accuracy:92.06349206349206Time:76
Test Loss:0.0063696139110347915Time:76
Training accuracy:100.0Time:77
Training Loss:0.00011823588979614906Time:77
Test accuracy:91.97012138188609Time:77
Test Loss:0.0107255271391597Time:77
Training accuracy:100.0Time:78
Training Loss:0.00011873815258738348Time:78
Test accuracy:92.06349206349206Time:78
Test Loss:0.011396435685073182Time:78
Training accuracy:100.0Time:79
Training Loss:0.00010554779317282563Time:79
Test accuracy:92.43697478991596Time:79
Test Loss:0.006405928778269935Time:79
Training accuracy:100.0Time:80
Training Loss:0.00010383624713767386Time:80
Test accuracy:92.34360410830999Time:80
Test Loss:0.010472912970933817Time:80
Training accuracy:100.0Time:81
Training Loss:0.00011490396933472376Time:81
Test accuracy:92.25023342670401Time:81
Test Loss:0.014451986823985779Time:81
Training accuracy:100.0Time:82
Training Loss:0.00010364585050705305Time:82
Test accuracy:92.53034547152194Time:82
Test Loss:0.004741446978571702Time:82
Training accuracy:100.0Time:83
Training Loss:0.00011216517964640116Time:83
Test accuracy:92.25023342670401Time:83
Test Loss:0.012893064126692343Time:83
Training accuracy:100.0Time:84
Training Loss:9.762327968761103e-05Time:84
Test accuracy:91.97012138188609Time:84
Test Loss:0.016287681657949638Time:84
Training accuracy:100.0Time:85
Training Loss:9.940918597333588e-05Time:85
Test accuracy:92.15686274509804Time:85
Test Loss:0.008370966693155126Time:85
Training accuracy:100.0Time:86
Training Loss:0.00014958986182279203Time:86
Test accuracy:91.22315592903828Time:86
Test Loss:0.004914389271028235Time:86
Training accuracy:100.0Time:87
Training Loss:0.00011439302132742138Time:87
Test accuracy:92.53034547152194Time:87
Test Loss:0.014856962707975443Time:87
Training accuracy:100.0Time:88
Training Loss:0.0001198182620135963Time:88
Test accuracy:92.99719887955182Time:88
Test Loss:0.017029843299217473Time:88
Training accuracy:100.0Time:89
Training Loss:0.00010403860299011029Time:89
Test accuracy:92.34360410830999Time:89
Test Loss:0.010878025094111538Time:89
Training accuracy:100.0Time:90
Training Loss:8.976515770579378e-05Time:90
Test accuracy:92.62371615312792Time:90
Test Loss:0.005922982672683331Time:90
Training accuracy:100.0Time:91
Training Loss:9.000677098904769e-05Time:91
Test accuracy:92.62371615312792Time:91
Test Loss:0.009474881668162056Time:91
Training accuracy:100.0Time:92
Training Loss:9.886574231307751e-05Time:92
Test accuracy:92.62371615312792Time:92
Test Loss:0.011246998214365499Time:92
Training accuracy:100.0Time:93
Training Loss:9.678739815352708e-05Time:93
Test accuracy:92.34360410830999Time:93
Test Loss:0.011591278204396992Time:93
Training accuracy:100.0Time:94
Training Loss:9.61153592002737e-05Time:94
Test accuracy:92.43697478991596Time:94
Test Loss:0.010736762865139545Time:94
Training accuracy:100.0Time:95
Training Loss:0.00010232292104573535Time:95
Test accuracy:92.81045751633987Time:95
Test Loss:0.015380823756911619Time:95
Training accuracy:100.0Time:96
Training Loss:7.99730308094878e-05Time:96
Test accuracy:92.43697478991596Time:96
Test Loss:0.012004685780358694Time:96
Training accuracy:100.0Time:97
Training Loss:7.648577691056221e-05Time:97
Test accuracy:92.15686274509804Time:97
Test Loss:0.005893917422112074Time:97
Training accuracy:100.0Time:98
Training Loss:8.695117870037203e-05Time:98
Test accuracy:93.37068160597572Time:98
Test Loss:0.007885190285220533Time:98
Training accuracy:100.0Time:99
Training Loss:0.00012094223208419264Time:99
Test accuracy:92.25023342670401Time:99
Test Loss:0.014352282890084745Time:99
